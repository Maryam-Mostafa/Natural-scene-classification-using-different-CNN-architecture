{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inception.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP465AR1jxzq0QfdOrBMnlg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maryam-Mostafa/Natural-scene-classification-using-different-CNN-architecture/blob/master/inception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tpIdMqqp_P7",
        "outputId": "30b38264-0673-458c-9dee-54f1798262fe"
      },
      "source": [
        "!pip install tflearn\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from random import shuffle\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "import matplotlib.pyplot as plt\n",
        "import tflearn\n",
        "from keras.utils import np_utils\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.estimator import regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import *\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "def Read_Data(path_,label,isTrain):\n",
        "    sub_data = []\n",
        "    for img in tqdm(os.listdir(path_)):\n",
        "        path = os.path.join(path_, img)\n",
        "        img_data = cv2.imread(path, 0)\n",
        "        img_data = cv2.resize(img_data, (150, 150))\n",
        "        if isTrain:\n",
        "          sub_data.append([np.array(img_data), label])\n",
        "        else:\n",
        "          sub_data.append([np.array(img_data), img])\n",
        "    return sub_data\n",
        "\n",
        "def Creat_all_train_data():\n",
        "    training_data,sub1,sub2,sub3,sub4,sub5,sub6 = [],[],[],[],[],[],[]\n",
        "          \n",
        "    sub1 = Read_Data(\"/content/drive/MyDrive/NNP/Scenetrainingset/buildings/\",0,True)\n",
        "    sub2 = Read_Data(\"/content/drive/MyDrive/NNP/Scenetrainingset/forest\",1,True)\n",
        "    sub3 = Read_Data(\"/content/drive/MyDrive/NNP/Scenetrainingset/glacier\",2,True)\n",
        "    sub4 = Read_Data(\"/content/drive/MyDrive/NNP/Scenetrainingset/mountain\",3,True)\n",
        "    sub5 = Read_Data(\"/content/drive/MyDrive/NNP/Scenetrainingset/sea\",4,True)\n",
        "    sub6 = Read_Data(\"/content/drive/MyDrive/NNP/Scenetrainingset/street\",5,True)\n",
        "    training_data = sub1 + sub2 + sub3 + sub4 + sub5 + sub6\n",
        "    shuffle(training_data)\n",
        "    np.save('/content/drive/MyDrive/NNP/train_dataset.npy', training_data)\n",
        "\n",
        "    return training_data\n",
        "\n",
        "def inception_module(layer_in, f1, f2, f3):\n",
        "    conv1 = Conv2D(f1, (1,1), padding='same', activation='relu')(layer_in)\n",
        "    conv3 = Conv2D(f2, (3,3), padding='same', activation='relu')(layer_in)\n",
        "    conv5 = Conv2D(f3, (5,5), padding='same', activation='relu')(layer_in)\n",
        "    pool = MaxPooling2D((3,3), strides=(1,1), padding='same')(layer_in)\n",
        "    layer_out = concatenate([conv1, conv3, conv5, pool], axis=-1)\n",
        "    return layer_out\n",
        "\n",
        "if (os.path.exists('/content/drive/MyDrive/NNP/train_dataset.npy')): \n",
        "    train =np.load('/content/drive/MyDrive/NNP/train_dataset.npy',allow_pickle=True)\n",
        "\n",
        "else: \n",
        "    train = Creat_all_train_data()\n",
        "\n",
        "if (os.path.exists('/content/drive/MyDrive/NNP/test_dataset.npy')): \n",
        "    test =np.load('/content/drive/MyDrive/NNP/test_dataset.npy',allow_pickle=True)\n",
        "\n",
        "else: \n",
        "      test = Read_Data(\"/content/drive/MyDrive/NNP/Scenestestingtest\",None,False)\n",
        "      np.save('/content/drive/MyDrive/NNP/test_dataset.npy', test)\n",
        "\n",
        "X_train = np.array([i[0] for i in train]).reshape(-1, 150, 150, 1)\n",
        "Y_train = np.array([i[1] for i in train])\n",
        "Y_train = np_utils.to_categorical(Y_train, num_classes=6)\n",
        "\n",
        "\n",
        "X_test = np.array([i[0] for i in test]).reshape(-1, 150, 150, 1)\n",
        "img_name = np.array([i[1] for i in test])\n",
        "\n",
        "#csvFile = pd.read_csv(\"/content/drive/MyDrive/NNP/submit.csv\")\n",
        "\n",
        "ops.reset_default_graph()\n",
        "\n",
        "conv_input = input_data(shape=[None, 150, 150, 1], name='input')\n",
        "\n",
        "inception1 = inception_module(conv_input , 32, 64, 32)\n",
        "inception2 = inception_module(inception2 , 32, 64, 32)\n",
        "\n",
        "fully_layer = fully_connected(inception2, 500, activation='relu')\n",
        "fully_layer = dropout(fully_layer, 0.5)\n",
        "\n",
        "cnn_layers = fully_connected(inception2, 6, activation='softmax')\n",
        "\n",
        "cnn_layers = regression(cnn_layers, optimizer='adam', learning_rate=0.01, loss='categorical_crossentropy', name='targets')\n",
        "model = tflearn.DNN(cnn_layers, tensorboard_dir='log', tensorboard_verbose=3)\n",
        "\n",
        "\n",
        "model.fit( X_train, Y_train, n_epoch=1,snapshot_step=100, show_metric=True, run_id='cnn')\n",
        "prediction = model.predict(X_test)\n",
        "prediction = np.argmax(prediction, axis=1)\n",
        "# print(prediction)\n",
        "\n",
        "rows = {'Image': [],'Label': []}\n",
        "csvFile = pd.DataFrame(rows, columns = ['Image', 'Label'])\n",
        "\n",
        "csvFile[\"Image\"] = img_name\n",
        "csvFile[\"Label\"] = np.asarray(prediction)\n",
        "csvFile.to_csv('submit3.csv')\n",
        "files.download('submit3.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tflearn in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from tflearn) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.19.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.15.0)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/initializations.py:165: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "---------------------------------\n",
            "Run id: cnn\n",
            "Log directory: log/\n",
            "INFO:tensorflow:Summary name Accuracy/ (raw) is illegal; using Accuracy/__raw_ instead.\n",
            "---------------------------------\n",
            "Training samples: 14034\n",
            "Validation samples: 0\n",
            "--\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}